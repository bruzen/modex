
-- implement Logical Replication in pre-9.4 postgres
--  also, this implementation is tuned to solve the specific problem of replicating to the web 
-- while 9.4 has Logical Replication, it a) conflicts with b) demands you poll (whereas CouchDB, whose filtered replication feature is what I'm trying to implement, [supports](http://couchdb.readthedocs.org/en/latest/replication/protocol.html#filter-replication) both pull ((long-)polling mode (the details of the long-polling variant are irrelevant to us; it's simply a workaround for HTTP being stupid, which we sidestep by not using HTTP at all)) and push ("streaming mode")



CREATE OR REPLACE LANGUAGE plpython2u;

-- DESIGN: abuse tables and triggers to construct event queues 
-- 
--  init_replicate(_table) sets watch() as a trigger on the given _table, if it is not already there
--   watch() formats changes as HRDJ (hobo-rowdelta json) format and writes to my_pg_replicate
--   my_pg_replicate is used as a queue; broadcast() is set as an INSTEAD OF trigger on it, stopping any data actually getting written to it; 
--   instead, broadcast() takes the HRDJ it received indirectly from watch() and copies it to all active clients; 
--  
--  on the "client" side, replicate(_table) first calls into the "server" side with init_replicate(_table), retrieving replicate_stream_id
--   then constructs a datagram (i.e. connectionless) socket to listen on, and calls into the "server" side 
--   register(replicate_stream_id, listen_addr)
--   which simply inserts that tuple into the table my_pg_replicate_{..??}

-- XXX replicate_stream_id is unclear at the moment; I know I need something like it to distinguish which feed of changes is being fed (at the moment, the only feeds are tables, but in the future we want to support distinct views, in order to be able to do /filtered/ replication).

--  
-- Much of the effort to go out of the way to use the DB itself as storage is because, presumably for security reasons, postgres runs multiple python processes (presumably the same is true for perl)--one per *client connection*. There is no way to just create global python objects and share them across all users. In particular, there's no way to create a pure python queue object for each client to listen on. However, that's what sockets are good for; plus, sockets (or, equivalently, a FIFO or a file) come with blocking built in for free (other options would require polling).
-- This restriction's probably a good thing. It also takes the complication of python-level concurrency out of the picture.

DROP TABLE IF EXISTS my_pg_replicate;
CREATE TABLE my_pg_replicate (event json);

CREATE OR REPLACE FUNCTION my_pg_replicate_broadcast() RETURNS trigger AS
$$
  """
  this trigger stops anything actually getting into the table
  """
  # TODO...
  print("[my_pg_replicate_broadcast()]: broadcasting ", TD["new"])
  return "SKIP"
$$ LANGUAGE plpython2u;

CREATE TRIGGER my_pg_replicate_trigger
  BEFORE INSERT  -- We only catch INSERT here, because we mean to
  ON my_pg_replicate -- maintain the invariant that this table is empty
  FOR EACH ROW
  EXECUTE PROCEDURE my_pg_replicate_broadcast();



-- "-_table" should eventually become "stream_id" with a spare table mapping stream_id to (table, columns, where)
DROP TABLE IF EXISTS my_pg_replicate_clients;
CREATE TABLE my_pg_replicate_clients (stream_id text PRIMARY KEY, addr text, _table text);

-- a simple data structure to refcount how many times each trigger is being listened to (ie how many clients are replicating each table)
--  refcounting is simple to implement; when the uses count drops to zero the trigger is deleted
DROP TABLE IF EXISTS my_pg_replicate_triggers;
CREATE TABLE my_pg_replicate_triggers (_table text PRIMARY KEY, trigger text, uses int);

--TODO: this function is simple enough that it could be done in plpgsql, which should be faster
CREATE OR REPLACE FUNCTION my_pg_replicate_register(addr text, _table text) RETURNS text AS
$$
  # returns the stream id for unregistering (& etc)
  
  import uuid
  stream_id = uuid.uuid4().hex
  
  plant = plpy.prepare("insert into my_pg_replicate_clients values ($1, $2, $3)", ["text", "text", "text"])
  plpy.execute(plant, [stream_id, addr, _table]);
  
  # this function should also install triggers on _table if they are not already there
  # XXX SQL injection
  r = plpy.execute("select _table from my_pg_replicate_triggers where _table = '%s'" % (_table,))
  #import IPython; IPython.embed()
  if r.nrows():
    #XXX SQL injection
    plpy.execute("update my_pg_replicate_triggers set uses = uses + 1 where _table = '%s'" % (_table,))
  else:
    # table is currently unwatched; generate a random name and install the trigger
    name = "watch_" + uuid.uuid4().hex
    plpy.execute(
    """CREATE TRIGGER %s
    AFTER INSERT OR UPDATE OR DELETE
    ON %s
    FOR EACH ROW
    EXECUTE PROCEDURE watch_table()
    """ % (name, _table))
    
    # record that the trigger is installed
    plpy.execute("insert into my_pg_replicate_triggers values ('%s', '%s', 1)" % (_table, name))
  
  return stream_id; 
$$ LANGUAGE plpython2u;

CREATE OR REPLACE FUNCTION my_pg_replicate_unregister(stream_id text) RETURNS bool AS
$$
  plant = plpy.prepare("delete from my_pg_replicate_clients where stream_id = $1", ["text"])
  plpy.execute(plant, [stream_id])
  return True; #TODO: check if the query did anything (?? does execute() return a list of affected rows or something we can look at?)
  
  # this function should also uninstall triggers if there are no listeners for _table left
$$ LANGUAGE plpython2u;