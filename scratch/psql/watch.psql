-- watch.psql
-- This postgres + pl/python2 script demonstrates watching changes to a table
-- This could be probably done in plpgsql, but I know python better, and it comes with serialization (json, msgpack, pickle) available easily.
-- these tips are from
--  http://www.postgresql.org/message-id/1405660725952-5811931.post@n5.nabble.com and
--  http://www.postgresql.org/message-id/1405703990457-5811982.post@n5.nabble.com
-- The reason I'm not using "Logical Decoding" <http://www.postgresql.org/docs/devel/static/logicaldecoding-example.html> is because it's still in devel---not even Arch Linux, usually full of bleeding edge code, has this feature yet. Plus it requires fiddling with the .conf file, same as replicant.py does, but in an incompatible way.


DROP TABLE IF EXISTS films CASCADE;
CREATE TABLE films (name text, kind text, rating int);
CREATE VIEW comedies AS select * from films where kind = 'Comedy'; --this from <http://www.postgresql.org/docs/current/static/sql-createview.html#SQL-CREATEVIEW-UPDATABLE-VIEWS>


-- other crippling bits: there's no way to set state (except, I suppose, through the DB itself)

CREATE LANGUAGE plpython2u; --will fail if python has already been loaded, but the script will continue

-- pl/ rules: each session has a correspond; so, every python script within this SQL script is run by the same interpreter (with the same globals, etc)
--  however, *other* sessions appear to launch *other* interpreters, even though the python code those sessions might end up triggering was set elsewhere.
-- the upshot of this, for us, is that we cannot rely on global variables or even global file descriptors.
-- http://www.postgresql.org/docs/9.3/static/plpython-sharing.html claims "Each function gets its own execution environment" but there's not total separation:


DROP FUNCTION IF EXISTS watch_table();
--'RETURNS trigger' is postgres speak for "this doesn't actually return a value but it's meant to be used as a trigger callback"
-- the main reference for this function is http://www.postgresql.org/docs/9.3/static/plpython-trigger.html
CREATE FUNCTION watch_table() RETURNS trigger AS $$ 
  # triggers do not have arguments passed
  # instead, pl/python passes the trigger data *and* any arguments given when you define the trigger in sub-members of the global variable TD
  
  table_name = TD["table_name"]
  FIFO = "_changes_%s" % (table_name,)
  import os
  FIFO = os.path.abspath(FIFO)
  if "FIFO" not in SD:
    #this is our first time running in this instance of the python interpreter:
    # run initializations
    
    #PL/Python is really meant for small one-off tasks, mostly. Most data should probably just be stuffed straight into the database.
    # however, things like file descriptors don't work so well like that
    # for these things, we need to use the facilities PL/python provides: http://www.postgresql.org/docs/9.3/static/plpython-sharing.html
    #  summary is: SD stands for "static data" and behaves like static locals in C (they must have some kind of trap table kicking around that switches in values of SD when the appropriate function is called).
    #              GD stands for "global data" and is the same everywhere
    #        both begin as empty dictionaries
    #   note also that it seems that one python interpreter is invoked ~per client connection~; not per-statement (which would be too fine) nor per
    import sys, os
    
    if os.path.exists(FIFO):
      #TODO: check that, if it exists, it's a FIFO and we have perms on it
      print("...it exists??", FIFO)
      print
      print(os.path.exists(FIFO))
      pass      
    else:
      print("attempting to construct fifo", FIFO)
      try:
        os.mkfifo(FIFO)
      except Exception as e:
        import traceback
        traceback.print_exc()
        print("couldn't make %s. ignoring" % FIFO)
        pass
    print('-'*30)
    # XXX problem: a nonblocking pipe cannot be opened until there is a reader to read it; the reader may go away after a moment and everything will be peachy, but startup is hard
    # ..hm.
    
    fd = os.open(FIFO, os.O_WRONLY | os.O_NONBLOCK) #O_NONBLOCK is key; otherwise, updates will *hang* the postgres process until someone open()s the FIFO
    FIFO = os.fdopen(fd, "w", 0) #OVERWRITES; buffering=1 means line buffered, and this is important since the default is to buffer at 4K which is too slow for our real-time purpose
    SD["FIFO"] = FIFO
    print "SD is now", SD
    

  import json
  
  FIFO = SD["FIFO"] #retrieve the FIFO from the static data, if this is our second (or even first) time around

  # ... when there's no consumers, shouldn't the prints get EPIPE?
  #print TD["table_name"], #<-- no newline
  print "Got triggered:", TD #, "locals=",locals(),"globals=",globals()
  # the output format here is:
  # a json object with a single "new" for an insert, a single "old" for a deletion, and both an "old" and a "new" for; beware that this makes the type of change *implicit*; it has the added bonus that it is reallllly simple to consume, since consumers can just look for an "old" tag, act on it, then for a "new" tag and act on that (but have the option of being more clever)
  # TODO: define some kind of remote primary key semantics and, for tables that have SQL primary keys, compress 'old' to only contain the PK, and in the case of an update, compress "new" to only contain the changed fields
  if TD["event"] == "INSERT":
    payload = {"+": TD["new"]}
  elif TD["event"] == "UPDATE":
    payload = {"-": TD["old"], "+": TD["new"]}
  elif TD["event"] == "DELETE":
    payload = {"-": TD["old"]}
  payload = json.dumps(payload)
  print >>FIFO, payload
$$ language plpython2u;


-- is there a way to list all defined triggers? probably by querying the right internal pg_* table..

CREATE TRIGGER watch_table_films
  AFTER INSERT OR UPDATE OR DELETE
  ON films
  FOR EACH ROW
  EXECUTE PROCEDURE watch_table();

-- this one is crippled because watching views doesn't help much
-- 1) triggers on a view only trigger if you actually said "UPDATE comedies SET ... WHERE ... ", not if you do "UPDATE films ..."
-- 2) triggers on a view *must* be "FOR EACH STATEMENT" unless you use "INSTEAD OF" but that would be something very different, then, and make using triggers and views and sql kind of pointless.
--CREATE TRIGGER watch_table_comedies
--  AFTER INSERT OR UPDATE OR DELETE
--  ON comedies
--  FOR EACH STATEMENT
--  EXECUTE PROCEDURE watch_table();

\COPY films FROM './films.sql'; -- COPY runs on the server, Hence, the client commanding the server to load a file *must give a full path*, because it doesn't know where the server is. Conversely, \COPY runs on the client, which, if the server is remote, might be a large amount of data. See <https://wiki.postgresql.org/wiki/COPY>

INSERT INTO films VALUES ('Grass', 'Documentary', 0);
INSERT INTO films VALUES ('The Mail Man', 'Documentary', 3);
DELETE FROM films WHERE name = 'Sallu Sue' or name = 'Seventy Days';
INSERT INTO films VALUES ('Superfly', 'Comedy', 5);
UPDATE films SET name = 'Ugly Ducks' WHERE rating < 5;

DROP MATERIALIZED VIEW IF EXISTS comedies_m;
CREATE MATERIALIZED VIEW comedies_m AS
  SELECT * FROM films WHERE kind = 'Comedy'
  WITH DATA;
--REFRESH MATERIALIZED VIEW comedies_m;

SELECT * FROM films;

-- this is illegal; you can attach triggers only to tables and to views (and views have extra restrictions)
-- 
--CREATE TRIGGER watch_comedies
--  AFTER INSERT OR UPDATE OR DELETE
--  ON comedies_m
--  FOR EACH STATEMENT
--  EXECUTE PROCEDURE watch_table();

-- CREATE TRIGGER watch_table_view
--  AFTER INSERT OR UPDATE OR DELETE
--  ON comedies
--  FOR EACH STATEMENT
--  EXECUTE PROCEDURE watch_table('comedies');

